{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inside-parcel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version 1.5.1+cu101\n",
      "Numpy Version 1.18.5 \n",
      "\n",
      "tensor([[ 75.,  63.,  48.],\n",
      "        [ 91.,  88.,  66.],\n",
      "        [ 84., 137.,  57.],\n",
      "        [108.,  41.,  36.],\n",
      "        [ 68.,  98.,  72.]])\n",
      "tensor([[ 54.,  71.],\n",
      "        [ 84., 111.],\n",
      "        [122., 143.],\n",
      "        [ 20.,  40.],\n",
      "        [101., 117.]]) \n",
      "\n",
      "tensor([[108.,  41.,  36.],\n",
      "        [ 91.,  88.,  66.],\n",
      "        [ 75.,  63.,  48.]])\n",
      "tensor([[ 20.,  40.],\n",
      "        [ 84., 111.],\n",
      "        [ 54.,  71.]]) \n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.0114,  0.4578, -0.0512],\n",
      "        [ 0.1528, -0.1745, -0.1135]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5516, -0.3824], requires_grad=True) \n",
      "\n",
      "Loss improved from inf to 7459.46\n",
      "Loss improved from 7459.46 to 5486.36\n",
      "Loss improved from 5486.36 to 3183.69\n",
      "Loss improved from 3183.69 to 1652.11\n",
      "Loss improved from 1652.11 to 937.11\n",
      "Loss improved from 937.11 to 636.37\n",
      "Loss improved from 636.37 to 347.09\n",
      "Loss improved from 347.09 to 46.10\n",
      "Loss improved from 46.10 to 44.47\n",
      "Loss improved from 44.47 to 36.42\n",
      "Loss improved from 36.42 to 31.78\n",
      "Loss improved from 31.78 to 30.93\n",
      "Loss improved from 30.93 to 25.83\n",
      "Loss improved from 25.83 to 25.61\n",
      "Loss improved from 25.61 to 24.75\n",
      "Loss improved from 24.75 to 24.43\n",
      "Loss improved from 24.43 to 23.43\n",
      "Loss improved from 23.43 to 16.79\n",
      "Loss improved from 16.79 to 9.95\n",
      "Loss improved from 9.95 to 8.25\n",
      "Loss improved from 8.25 to 8.00\n",
      "Loss improved from 8.00 to 6.85\n",
      "\n",
      "Best Loss: 6.85\n",
      "\n",
      "key:  weight\n",
      "tensor([[-0.1638,  0.9333,  0.2080],\n",
      "        [ 0.0399,  0.8696,  0.3537]])\n",
      "key:  bias\n",
      "tensor([-0.5510, -0.3802])\n"
     ]
    }
   ],
   "source": [
    "######################## PyTorch Implementation of Linear Regression with a Toy Problem #####################\n",
    "\n",
    "# Import different packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print('PyTorch Version',torch.__version__)\n",
    "print('Numpy Version',np.__version__,'\\n')\n",
    "################################################################\n",
    "torch.manual_seed(0)   #You can use torch.manual_seed() to seed the RNG for all devices (both CPU and CUDA)\n",
    "random.seed(0)         #For custom operators, you might need to set python seed\n",
    "np.random.seed(0)      #If you or any of the libraries you are using rely on NumPy, you can seed the global NumPy RNG\n",
    "################################################################\n",
    "\n",
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    best_loss = np.Inf\n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Save best model based on loss\n",
    "            if loss.detach().numpy() < best_loss:\n",
    "                print('Loss improved from {:.2f} to {:.2f}'.format(best_loss,loss.detach().numpy()))\n",
    "                best_loss = loss.detach().numpy()\n",
    "                \n",
    "                torch.save(model, 'best_linreg_model.pth')\n",
    "            \n",
    "            # 4. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 5. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 6. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) == num_epochs:\n",
    "            #print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            print('\\nBest Loss: {:.2f}\\n'.format(best_loss))\n",
    "            model = torch.load('best_linreg_model.pth')\n",
    "            \n",
    "            for key in model.state_dict():\n",
    "                print('key: ', key)\n",
    "                param = model.state_dict()[key]\n",
    "                print(param)\n",
    "\n",
    "                \n",
    "######################################################################            \n",
    "# Input (x, y, z)\n",
    "inputs = np.array([[75, 63, 48], \n",
    "                   [91, 88, 66], \n",
    "                   [84, 137, 57], \n",
    "                   [108, 41, 36], \n",
    "                   [68, 98, 72]], dtype='float32')\n",
    "\n",
    "# Targets (a, b)\n",
    "targets = np.array([[54, 71], \n",
    "                    [84, 111], \n",
    "                    [122, 143], \n",
    "                    [20, 40], \n",
    "                    [101, 117]], dtype='float32')\n",
    "\n",
    "# Convert inputs and targets to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets,'\\n')\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]\n",
    "\n",
    "# Define data loader\n",
    "batch_size = 3  # should be << number of observations\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "\n",
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb,'\\n')\n",
    "    break\n",
    "\n",
    "    \n",
    "###########################################################################\n",
    "# Define model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias,'\\n')\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "# SGD Optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "banned-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 55.9501,  74.3751],\n",
       "        [ 80.4069, 103.1202],\n",
       "        [125.4135, 142.2679],\n",
       "        [ 27.5171,  52.3162],\n",
       "        [ 94.7545, 113.0206]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "model = torch.load('best_linreg_model.pth')\n",
    "model.eval()\n",
    "\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adaptive-association",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 54.,  71.],\n",
       "        [ 84., 111.],\n",
       "        [122., 143.],\n",
       "        [ 20.,  40.],\n",
       "        [101., 117.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual outputs\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "settled-representation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[57.0600, 73.8723]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inferencing a given input\n",
    "model(torch.tensor([[72, 65, 42.]]))  #testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spatial-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:  weight\n",
      "tensor([[-0.1638,  0.9333,  0.2080],\n",
      "        [ 0.0399,  0.8696,  0.3537]])\n",
      "key:  bias\n",
      "tensor([-0.5510, -0.3802])\n"
     ]
    }
   ],
   "source": [
    "# Verify the best model's weights and bias\n",
    "for key in model.state_dict():\n",
    "    print('key: ', key)\n",
    "    param = model.state_dict()[key]\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-eleven",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
